{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting CIK for every company in the s&p 500 from wikipedia\n",
    "wiki_url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "cik_df = pd.read_html(wiki_url, header=0, index_col=0)[0]\n",
    "\n",
    "cik_list = cik_df['CIK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=66740&type=8-K&output=xml&dateb=20200430&datea=20150501&start=&count=100\n"
     ]
    }
   ],
   "source": [
    "# defining endpoint and parameters for every company in the s&p\n",
    "url = 'https://www.sec.gov/cgi-bin/browse-edgar'\n",
    "params = {'action': 'getcompany', \n",
    "          'CIK': 66740, \n",
    "          'type': '8-K', \n",
    "          'output':'xml', \n",
    "          'dateb': '20200430',\n",
    "          'datea': '20150501',\n",
    "          'start': '',\n",
    "          'count': '100'}\n",
    "\n",
    "# getting response from EDGAR database\n",
    "sec_response = requests.get(url=url, params=params)\n",
    "\n",
    "# printing status code and url to check if its working\n",
    "print(sec_response.status_code)\n",
    "print(sec_response.url)\n",
    "\n",
    "# creating soup to parse xml\n",
    "soup = BeautifulSoup(sec_response.content, 'xml')\n",
    "\n",
    "# getting link to 8-k document\n",
    "urls = soup.findAll('filingHREF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.sec.gov/Archives/edgar/data/66740/000110465920051945/0001104659-20-051945-index.htm'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[0].string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_list = []\n",
    "\n",
    "# html version of links\n",
    "for url in urls:\n",
    "    url = url.string\n",
    "    \n",
    "    if url.split('.')[len(url.split('.'))-1] == 'htm':\n",
    "        txt_link = url + 'l'\n",
    "        html_list.append(txt_link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = []\n",
    "doc_list_names = []\n",
    "doc_df = pd.DataFrame()\n",
    "\n",
    "# links to 8-k text\n",
    "for html in html_list:\n",
    "    txt_doc = html.replace(\"-index.html\",\".txt\")\n",
    "    doc_name = txt_doc.split(\"/\")[-1]\n",
    "    doc_list.append(txt_doc)\n",
    "    doc_name_list.append(doc_name)\n",
    "    \n",
    "# creating dataframe to append each company\n",
    "    df = pd.DataFrame(\n",
    "                {\"cik\" : [cik]*len(html_list),\n",
    "                \"ticker\" : [ticker]*len(html_list),\n",
    "                \"txt_link\" : doc_list,\n",
    "                \"doc_name\": doc_name_list})\n",
    "    \n",
    "    doc_df.append(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
